{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "In this notebook, I implemented k-nearest neighbors regression:\n",
    "  * Find the k-nearest neighbors of a given query input\n",
    "  * Predict the output for the query input using the k-nearest neighbors\n",
    "  * Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of the King County housing dataset created by randomly selecting 40% of the houses in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphLab Create"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data_small.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some important function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently compute pairwise distances among data points, we will convert the SFrame into a 2D Numpy array. First import the numpy library and then copy and paste `get_numpy_data()` from the second notebook of Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output): # features and output are list here\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features]\n",
    "\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the `normalize_features()` function from Week 5 that normalizes all feature columns to unit norm. Paste this function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = feature_matrix / norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_and_validation, test) = sales.random_split(.8, seed=1) # initial train/test split\n",
    "(train, validation) = train_and_validation.random_split(.8, seed=1) # split training set into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all of the numerical inputs listed in `feature_list`, transform the training, test, and validation SFrames into Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "Norms of the features are stored in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the \"distance\" between two given houses.  We will take our **query house** to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345386 -0.01346927  0.01375926  0.0016225 ]\n"
     ]
    }
   ],
   "source": [
    "print features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the 10th row (index 9) of the training feature matrix. Again, you get an 18-dimensional vector with components between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346254  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print features_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0597235937167\n"
     ]
    }
   ],
   "source": [
    "d = features_test[0] - features_train[9]\n",
    "dd = d**2\n",
    "dd1 = np.sqrt(np.sum(dd))\n",
    "print dd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the Numpy functions can be **vectorized**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that computes the distances from a query house to all training houses. The function should take two parameters: (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ed(trng, vec):\n",
    "    diff =trng[0:len(trng)] -  vec\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    return distances\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "\n",
    "1.  Take the query house to be third house of the test set (`features_test[2]`).  What is the index of the house in the training set that is closest to this query house?\n",
    "2.  What is the predicted value of the query house based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00286049526751\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "d = ed(features_train, features_test[2])\n",
    "min_d = min(d)\n",
    "index =d.argmin()\n",
    "print min_d\n",
    "print index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a *set* of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors\n",
    "\n",
    "Using the functions above, a function is written that takes in \n",
    " * the value of k;\n",
    " * the feature matrix for the training houses; and\n",
    " * the feature vector of the query house\n",
    " \n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(trnmat, qmat,k):\n",
    "    #for u in xrange(0,len(qmat)):\n",
    "    diff =trnmat[0:len(trnmat)] -  qmat\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    index = np.argsort(distances)\n",
    "    nearest = index[0:k]\n",
    "    return nearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set**. The function should have the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def knnp(trnmat, qmat,k,train):\n",
    "    r = np.zeros(k)\n",
    "    diff =trnmat[0:len(trnmat)] -  qmat\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    index = np.argsort(distances)\n",
    "    nearest = index[0:k]\n",
    "    for s in range(0,len(nearest)):\n",
    "        r[s] = train[nearest[s]]+r[s]\n",
    "        predict= np.sum(r)/len(r)\n",
    "    return predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is written to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function takes the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set.\n",
    " \n",
    "The function should return a set of predicted values, one for each house in the query set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knnp(trnmat, qmat,k,train):\n",
    "    predict = np.zeros(len(qmat))\n",
    "    for w in xrange(0,len(qmat)):        \n",
    "        r = np.zeros(k)\n",
    "        diff =trnmat[0:len(trnmat)] -  qmat[w]\n",
    "        distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "        index = np.argsort(distances)\n",
    "        nearest = index[0:k]\n",
    "        for s in range(0,len(nearest)):\n",
    "            r[s] = train[nearest[s]]+r[s]\n",
    "            predict[w] = np.sum(r)/len(r)\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function is written to predict first 10 houses in the test set using k-nearest neighbors with `k=10`. \n",
    "and give output of house with lowest predicted value and its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 881300.   431860.   460595.   430200.   766750.   667420.   350032.\n",
      "  512800.7  484000.   457235. ]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "t = knnp(features_train, features_test[0:10],10,output_train)\n",
    "print t\n",
    "print t.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We use a validation set to choose this value.A loop is written that does the following:\n",
    "\n",
    "# For `k` in [1, 2, ..., 15]:\n",
    "    # Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    # Computes the RSS for these predictions on the VALIDATION set\n",
    "    # Stores the RSS computed above in `rss_all`\n",
    "# Report which `k` produced the lowest RSS on VALIDATION set.\n",
    "\n",
    "\n",
    "\n",
    "def knnp1(trnmat, qmat,k,train,validn):\n",
    "    predict = np.zeros(len(qmat))\n",
    "    rss = np.zeros(len(qmat))\n",
    "    for w in xrange(0,len(qmat)):        \n",
    "        r = np.zeros(k)\n",
    "        diff =trnmat[0:len(trnmat)] -  qmat[w]\n",
    "        distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "        index = np.argsort(distances)\n",
    "        nearest = index[0:k]\n",
    "        for s in range(0,len(nearest)):\n",
    "            r[s] = train[nearest[s]]+r[s]\n",
    "            predict[w] = np.sum(r)/len(r)\n",
    "            rss[w] = (validn[w] - predict[w])*(validn[w] - predict[w])\n",
    "    res = np.sum(rss)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "rss_all = np.zeros(35)\n",
    "for s in range(1,35):\n",
    "    rss_all[s] = knnp1(features_train, features_valid[0:1434],(s),output_train,output_valid)\n",
    "return rss_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To visualize the performance as a function of `k`, plot the RSS on the VALIDATION set for each considered `k` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  8  7  9  6 12 10 11  5 13 16 14 17 15 18  4 19 20  3 21 22 23 24 25 26\n",
      " 27 28 29 30 31 33 34 32  2  1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf071ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "kvals = range(1,36)\n",
    "plt.plot(kvals, rss_all,'bo-')\n",
    "print rss_all.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# curve flatens out after k = 3 . Rss value on test set for k = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rss_test = knnp1(features_train, features_valid[0:1740],3,output_train,output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353957570304403.56"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****end*****"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [gl-env]",
   "language": "python",
   "name": "Python [gl-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
